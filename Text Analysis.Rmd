---
title: "MA615 Assignment4 Text Analysis"
author: "Kosuke Sasaki"
date: "2021/12/7"
output: pdf_document
csl: nature.csl
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.pos = 'h')
Sys.setenv("LANGUAGE" = "EN")
Sys.setlocale("LC_ALL", "C")
library(gutenbergr)
library(dplyr)
library(tidytext)
library(scales)
library(stringr)
library(ggplot2)
library(tidyr)
library(tnum)
library(knitr)
library(kableExtra)
library(magrittr)
library(tidyverse)
library(textdata)
library(sentimentr)
library(ndjson)
library(gridExtra)
```


# I. Bag of Words Analysis
## Sentiment analysis based on AFINN, BIN, and NRC scale
I have chosen "The Jungle Book" as my book from the gutenberg ebooks. 
Then, three different lexicons, "Afinn", "Bing", and "Nrc" are used to calculate sentiment of the books.
I counted up how many positive and negative words there are in defined sections of each book. I define an index to keep track of the book, and this index counts up sections of 80 lines of text. An estimate of the net sentiment (positive - negative) in each chunk of the book for each sentiment lexicon are shown in the Figure 1.


```{r,message=FALSE,warning=FALSE,echo=FALSE}
# download "jungle book" from gutenberg and store it as data.frame
junglebook<- gutenberg_download(236)

# separate each line into words and make the tidy data frame
tidyjungle <- junglebook %>%
  mutate(linenumber = row_number()) %>%
  unnest_tokens(word, text)

# make data frame for sentiment analysis on "afinn" scale 
afinn <- tidyjungle %>% 
  inner_join(get_sentiments("afinn")) %>% #add sentiment attribute to each word in "tidyjungle"
  # make 80 lines as a chunk
  group_by(index = linenumber %/% 80) %>% 
  #sums up sentiment values for each chunk
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN") 
    
# make data frame for sentiment analysis on "bing" scale as with "afinn" scale
bing <- tidyjungle %>%
  inner_join(get_sentiments("bing")) %>% 
  count(index = linenumber %/% 80, sentiment) %>% 
  # change data frame from long to wide format
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  # calculate sentiment score
  mutate(sentiment = positive - negative)%>% 
  mutate(method = "BING")

# make data frame for sentiment analysis on "nrc" scale as with "bing" scale
nrc <- tidyjungle %>%
  inner_join(get_sentiments("nrc"))%>%
  count(index = linenumber %/% 80, sentiment)%>% 
  filter(sentiment %in% c("positive", "negative"))%>%
 pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative) %>% 
  mutate(method = "NRC")

# bind all the above data and visualize sentiment score for each chunk by sentiment scale
bind <- bind_rows(afinn, bing, nrc) 
  grid.arrange(ggplot(bind,aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
  ,bottom="Fig.1 Comparison of three sentiment lexicons")
```
The three different lexicons seem to produce results with some similar trajectories; we have more negative values than positive values throughout the book. Still, we have also some differences between them. The AFINN lexicon gives the largest absolute values, with high negative values. The Bing lexicon has very few positive values. The NRC lexicon seems to label the text more positively relative to the other two. 
These differences between the methods are seen when looking at other books; the NRC sentiment is high, the AFINN sentiment has more variance, the Bing et al. sentiment appears to find longer stretches of similar text.[1]

## Words count based on each sentiment scale  
Then I compare the word counts which contribute to sentiment.  
```{r,message=FALSE,warning=FALSE,echo=FALSE}
# create dataframe including counts of sentiment words on "afinn" scale
afinn_word_counts <- tidyjungle %>%
  inner_join(get_sentiments("afinn")) %>%
  #categorize words into positive and negative based on sentiment value 
  mutate(sentiment=ifelse(value>0,"positive","negative")) %>% 
  count(word, sentiment, sort = TRUE)
# plot  sentiment word counts based on afinn scale 
afinn_word_counts %>%
  group_by(sentiment) %>% #group poitive and negative words
  slice_max(n, n = 10) %>% #extract top 10 words for each sentiment
  ungroup() %>%
  mutate(word = reorder(word, n)) %>% # sort rows based on the word counts
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Fig.2-1 Contribution to sentiment (AFINN)",
       y = NULL)

# create dataframe including counts of sentiment words on "bing" scale
bing_word_counts <- tidyjungle %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE)
# plot  sentiment word counts based on bing scale 
bing_word_counts %>%
  group_by(sentiment) %>% #group poitive and negative words
  slice_max(n, n = 10) %>% #extract top 10 words for each sentiment
  ungroup() %>%
  mutate(word = reorder(word, n)) %>% # sort rows based on the word counts
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Fig.2-2 Contribution to sentiment (BING)",
       y = NULL)

# create dataframe including counts of sentiment words on "nrc" scale
nrc_word_counts <- tidyjungle %>%
  inner_join(get_sentiments("nrc")) %>%
  #pick up only positive and negative words 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(word, sentiment, sort = TRUE)
# plot  sentiment word counts based on afinn scale 
nrc_word_counts %>%
  group_by(sentiment) %>% #group poitive and negative words
  slice_max(n, n = 10) %>% #extract top 10 words for each sentiment
  ungroup() %>%
  mutate(word = reorder(word, n)) %>% # sort rows based on the word counts
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Fig.2-3 Contribution to sentiment (NRC)",
       y = NULL)
```
As we can see from the figure2-1 to figure2-3, there are several words (kill, dead, like, good, so on so forth) common to the lexicons but the ratio of positive and negative words are different. In addition, the most frequent negative word "nag" on NRC scale is a name of a character and could lead to misleading result of sentiment analysis. Based on these results, there is a chance to choose a lexicon which does not match the word choices of this jungle book so that I should carefully choose the appropriate lexicon in order to draw figure 1 trajectory which best describes the outline of the book.  

## Additional lexicon analysis
In addition to the lexicon of Afinn, Bing, and Nrc, I tried to apply nrc_eil lexicon to sentiment analysis as below.
```{r,message=FALSE,warning=FALSE,echo=FALSE}
#Download the lexicon of nrc_eil and store it as a data frame
nrceil <- lexicon_nrc_eil() %>% rename(word=term)
#assign positive sign to "joy" and negative sign to "anger", "fear" and "sadness"
nrceil <- nrceil %>% 
  mutate(value=ifelse(nrceil$AffectDimension=="joy",
                      nrceil$score,-1*nrceil$score), sentiment=ifelse(nrceil$AffectDimension=="joy","positive","negative")) %>% 
  select(word, value, sentiment)

# make data frame for sentiment analysis on "nrc_eil" scale 
nrc_eil <- tidyjungle %>% 
  inner_join(nrceil) %>% #add sentiment attribute to each word in "tidyjungle"
  # make 80 lines as a chunk
  group_by(index = linenumber %/% 80) %>% 
  #sums up sentiment values for each chunk
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "NRC_EIL") 

#visualize sentiment score for each chunk by nrc_eil scale
  grid.arrange(ggplot(nrc_eil, aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE),
  bottom="Fig.3-1 NRC_EIL trajectory")

# create dataframe including counts of sentiment words on "nrceil" scale
nrceil_word_counts <- tidyjungle %>%
  inner_join(nrceil) %>%
  count(word, sentiment, sort = TRUE)
# plot  sentiment word counts based on bing scale 
nrceil_word_counts %>%
  group_by(sentiment) %>% #group poitive and negative words
  slice_max(n, n = 10) %>% #extract top 10 words for each sentiment
  ungroup() %>%
  mutate(word = reorder(word, n)) %>% # sort rows based on the word counts
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Fig.3-2 Contribution to sentiment (NRC_EIL)",
       y = NULL)
```
As you can see Figure3-1 and 3-2, nrc_eil lexicon shows much more negative words than positive words relative to other lexicons . This is because nrc_eil lexicon categorize words into 4 types, "joy", "anger", "fear", and "sadness", and I assume "joy" is the positive category and the others as negative category, which leads to more negative sentiment values assigned to the book.

##Comparison of visualization of lexicons and plotline
The plotline of this book is basically not so happy because the main character "Mowgli" has experienced a lot of hardship, even though he and his friends sometimes experienced success, throughout the story. In that sense, NRC lexicon would not be appropriate because it shows rather a positive trajectory, and it also includes the negative word "nag", which is actually used as a character name in the book. The trajectories of Afinn and Bing lexicon seem to be aligned with the storyline but Bing one shows too many negative sentiment values considering there is still some success. So I would choose Afinn lexicon as the most appropriate one for this book.

# II. Paragraph-level of Analysis  
In this section, I will do sentiment analysis using "truenumber" and "sentimentr" as below.  

```{r,message=FALSE,warning=FALSE,echo=FALSE}
# access the truenumber space of "test2" 
tnum.authorize("mssp1.bu.edu")
tnum.setSpace("test2")

# # Convert the text columns into a text file and enclose headings with <>
# write_lines(junglebook$text, "junglebooktext")
# # Read in the text as a list
# junglebook_txt <- readLines("junglebooktext")
# 
# # Source function to upload the text to truenumber space
# source("Book2TN-v6A-1.R")
# # Upload the text to the space
# tnBooksFromLines(junglebook_txt, "Kipling4/junglebook4")

# # Add tags"Mogli" and "Shere Khan" to the truenumber 
# tnum.tagByQuery("Kipling4/junglebook4# has *=REGEXP(\" Mowgli\")",
#                adds=("Mowgli"))
# tnum.tagByQuery("Kipling4/junglebook4# has *=REGEXP(\" Shere Khan\")",
#                adds=("Shere Khan"))

# Extract all the text of the book excluding heading as a list
wt <- tnum.query("Kipling4/junglebook4/section:# has text", max=3000)
#Turn the list into a data frame
dft<- tnum.objectsToDf(wt)
# Extract the location of each sentence as a list and change it as a data frame
wo <- tnum.query("Kipling4/junglebook4/section:# has ordinal", max=3000)
dfo <- tnum.objectsToDf(wo)
# Extract word counts of each sentence as a list and change it as a data frame
wc <- tnum.query("Kipling4/junglebook4/section:# has count:#", max=3000)
dfc <- tnum.objectsToDf(wc) %>% rename(wordcounts=numeric.value)

# Make the data frame of all the text, location,and wordcounts without heading
text_locations <- left_join(select(dft, subject, string.value, tags), 
                               select(dfo, subject, numeric.value)) %>%
                  left_join(select(dfc, subject, wordcounts))

# Separate the subject column into "section", "paragraph" and "sentence"
tnumtext <- text_locations %>% 
  separate(col = subject, sep = "/para", into = c("section", "para")) %>%
  separate(col = section, sep = ":", into = c("out","section")) %>%
  separate(col = para, sep = "/", into = c("pars","sent"))%>%
  separate(col = pars, sep = ":", into = c("out1","paragraph"))%>%
  separate(col = sent, sep = ":", into = c("out2","sentence"))%>%
  rename(ordinal = numeric.value) %>% select(!c(out,out1,out2))
#To do paragraph analysis, assign serial paragraph number
tnumtext <- tnumtext %>% unite(col = "secpara", section, paragraph, remove= FALSE)
paran <- nrow(distinct(tnumtext, secpara))
a <- data.frame(secpara=distinct(tnumtext, secpara),
                serialpara=c(1:paran))
tnumtext <- left_join(tnumtext,a, by="secpara") %>% select(!"secpara")
#remove tentative data set
rm(a)


#create tentative data frame
sentimentvalue <- data.frame(NULL)
#Calculate sentiment value for each paragraph
for (i in 1:paran) {
paratext <- tnumtext %>% filter(serialpara == i) %>% 
  pull(string.value) %>% str_replace_all("\"","") %>%
  str_flatten(collapse = " ")
parasentence <- get_sentences(paratext)
a <- sentiment_by(parasentence)
sentimentvalue <- rbind(sentimentvalue, a)
}
#Add paragraph column to "sentimentvalue" data frame
sentimentvalue <- sentimentvalue %>% 
  mutate(paragraph=c(1:paran), method="SENTIMENTR") %>%
  rename(sentiment=ave_sentiment) %>%
  select(paragraph,sentiment,method)
#remove tentative data set in the for loop
rm(a,papratext,parasentence)

# plot the sentiment values calculated by "sentimentr" through paragraphs
grid.arrange(ggplot(sentimentvalue,aes(paragraph, sentiment)) +
  geom_col(show.legend = FALSE),
  bottom="Fig.4 Sentimentr trajectory by paragraph")
```
  
  
For this analysis, I calculated sentiment value for each paragraph, while I used keep track of the book for each section of 80 lines of text in the "I. Bag of Words Analysis" section. In total, there are 876 paragraphs and the trajectory of sentiment value by sentimentr analysis is shown above as Figure4.  
  
  
## comparison between sentimentr and lexicons as Paragraph-level Analysis  
I will compare the trajectories between sentimentr and lexicons as paragraph-level analysis. To do that, I re-do the bag of words analysis for each lexicon as below.  

```{r,message=FALSE,warning=FALSE,echo=FALSE}
# separate each line into words and make the tidy data frame of tnum
tidytnumtext <- tnumtext %>%
  unnest_tokens(word, string.value)

# make data frame for sentiment analysis on "afinn" scale 
afinn2 <- tidytnumtext %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(paragraph=serialpara) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN") 
    
# make data frame for sentiment analysis on "bing" scale as with "afinn" scale
bing2 <- tidytnumtext %>%
  inner_join(get_sentiments("bing")) %>% 
  count(paragraph=serialpara, sentiment) %>% 
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(sentiment = positive - negative)%>% 
  mutate(method = "BING")

# make data frame for sentiment analysis on "nrc" scale as with "bing" scale
nrc2 <- tidytnumtext %>%
  inner_join(get_sentiments("nrc"))%>%
  count(paragraph=serialpara, sentiment)%>% 
  filter(sentiment %in% c("positive", "negative"))%>%
 pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative) %>% 
  mutate(method = "NRC")

# plot the sentiment values based on lexicons and sentimentr through paragraphs
bindrow <- bind_rows(sentimentvalue, afinn2, bing2, nrc2)
 grid.arrange(ggplot(bindrow, aes(paragraph, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y"),
  bottom="Fig.5 Comparison of lexicons and sentimentr by paragraph")
```
  
Based on the figure5 above, the trajectory calculated by sentimentr for each graph looks similar to the ones by three lexicons. Even though, when you take a closer look, NRC trajectory shows more positive values relative to the other trajectories, which we could see in the comparison of three lexicons in the first section of this report. Compared to Afinn and Bing trajectories, sentimentr one is small in absolute value but the shape is very similar to those two trajectories, just as in-between.  
Given these graphs, I could say Afinn, Bing and sentimentr are all appropriate for the sentiment analysis for this book.

# III. Character Analysis  
Finally, I will calculate sentiment value related to "Mowgli", the main character of this book, and "Shere Khan", Mowgli's opponent.  

```{r,message=FALSE,warning=FALSE,echo=FALSE}
# Already add tags to truenumber in the section II with the below codes
# and downloaded it as tnumtext
# tnum.tagByQuery("Kipling4/junglebook4# has *=REGEXP(\" Mowgli\")",
#                adds=("Mowgli"))
# tnum.tagByQuery("Kipling4/junglebook4# has *=REGEXP(\" Shere Khan\")",
#                adds=("Shere Khan"))
mowgli <- tnumtext %>% filter(tags=="Mowgli")
shere <- tnumtext %>% filter(tags=="Shere Khan")

#calculate the sentiment value related to "Mowgli" for each sentence
mowglisenti <- mowgli %>% 
  pull(string.value) %>% str_replace_all("\"","") %>%
  str_flatten(collapse = " ") %>% 
  get_sentences() %>% 
  sentiment()
#Plot the sentiment value related "Mowgli" for each sentence
grid.arrange(ggplot(mowglisenti,aes(sentence_id, sentiment)) +
  geom_col(show.legend = FALSE),
  bottom="Fig.6-1 Mowgli sentiment trajectory by paragraph")
 
 
#calculate the sentiment value related to "Shere Khan" for each sentence
sheresenti <- shere %>% 
  pull(string.value) %>% str_replace_all("\"","") %>%
  str_flatten(collapse = " ") %>% 
  get_sentences() %>% 
  sentiment()
#Plot the sentiment value related "Shere Khan" for each sentence
grid.arrange(ggplot(sheresenti,aes(sentence_id, sentiment)) +
  geom_col(show.legend = FALSE),
  bottom="Fig.6-2 Shere Khan sentiment trajectory by paragraph")


#Calculate average sentiment value related to Mowgli and Shere Khan separately
mowglisenti %>% sentiment_by()
sheresenti %>% sentiment_by()
```
  
As you can see from Figure6-1 and 6-2, the sentences related to Mowgli are much more than the ones related to Shere Khan. It is reasonable because Mowgli is the main character whereas Shere Khan is his opponent and the number of appearance in the story is much less than that of Mowgli. It is also reasonable that trajectory of Shere Khan seems to be slightly more negative than the one of Mowgli, and the average of sentiment value of Shere Khan based on sentimentr is -0.04, which is less than that of Mowgli, -0.02, which you can see in the above tables.  
In conclusion, sentiment analylsis based on sentimentr function works really well for this book.  
  
# Reference
1. Julia, S. (2021) *Text Mining with R: A Tidy Approach*[online]. Oâ€™Reilly: https://www.tidytextmining.com/index.html
  [accessed 7 December 2021]
